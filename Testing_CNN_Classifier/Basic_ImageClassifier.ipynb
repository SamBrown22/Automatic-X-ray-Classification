{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependancies\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Organising Data from Cifar10 dataset\n",
    "(X_train, Y_train), (X_test, Y_test) = datasets.cifar10.load_data()\n",
    "\n",
    "#Takes the 2D array and converts to 1D\n",
    "Y_train = Y_train.reshape(-1,)\n",
    "\n",
    "#Divide each pixel value by 255 to normalise in a 0 to 1 range\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "#The classification word associated to each output Y of each input X\n",
    "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "#Method to Plot the image with its classification\n",
    "def plot_sample(X, Y, index):  \n",
    "    plt.figure(figsize = (20,2)) #Changes image size\n",
    "    plt.imshow(X[index], interpolation='bilinear') #plots the image\n",
    "    plt.xlabel(classes[Y[index]]) #Adds a label for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.23137255, 0.24313725, 0.24705882],\n",
       "         [0.16862745, 0.18039216, 0.17647059],\n",
       "         [0.19607843, 0.18823529, 0.16862745],\n",
       "         ...,\n",
       "         [0.61960784, 0.51764706, 0.42352941],\n",
       "         [0.59607843, 0.49019608, 0.4       ],\n",
       "         [0.58039216, 0.48627451, 0.40392157]],\n",
       "\n",
       "        [[0.0627451 , 0.07843137, 0.07843137],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.07058824, 0.03137255, 0.        ],\n",
       "         ...,\n",
       "         [0.48235294, 0.34509804, 0.21568627],\n",
       "         [0.46666667, 0.3254902 , 0.19607843],\n",
       "         [0.47843137, 0.34117647, 0.22352941]],\n",
       "\n",
       "        [[0.09803922, 0.09411765, 0.08235294],\n",
       "         [0.0627451 , 0.02745098, 0.        ],\n",
       "         [0.19215686, 0.10588235, 0.03137255],\n",
       "         ...,\n",
       "         [0.4627451 , 0.32941176, 0.19607843],\n",
       "         [0.47058824, 0.32941176, 0.19607843],\n",
       "         [0.42745098, 0.28627451, 0.16470588]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.81568627, 0.66666667, 0.37647059],\n",
       "         [0.78823529, 0.6       , 0.13333333],\n",
       "         [0.77647059, 0.63137255, 0.10196078],\n",
       "         ...,\n",
       "         [0.62745098, 0.52156863, 0.2745098 ],\n",
       "         [0.21960784, 0.12156863, 0.02745098],\n",
       "         [0.20784314, 0.13333333, 0.07843137]],\n",
       "\n",
       "        [[0.70588235, 0.54509804, 0.37647059],\n",
       "         [0.67843137, 0.48235294, 0.16470588],\n",
       "         [0.72941176, 0.56470588, 0.11764706],\n",
       "         ...,\n",
       "         [0.72156863, 0.58039216, 0.36862745],\n",
       "         [0.38039216, 0.24313725, 0.13333333],\n",
       "         [0.3254902 , 0.20784314, 0.13333333]],\n",
       "\n",
       "        [[0.69411765, 0.56470588, 0.45490196],\n",
       "         [0.65882353, 0.50588235, 0.36862745],\n",
       "         [0.70196078, 0.55686275, 0.34117647],\n",
       "         ...,\n",
       "         [0.84705882, 0.72156863, 0.54901961],\n",
       "         [0.59215686, 0.4627451 , 0.32941176],\n",
       "         [0.48235294, 0.36078431, 0.28235294]]],\n",
       "\n",
       "\n",
       "       [[[0.60392157, 0.69411765, 0.73333333],\n",
       "         [0.49411765, 0.5372549 , 0.53333333],\n",
       "         [0.41176471, 0.40784314, 0.37254902],\n",
       "         ...,\n",
       "         [0.35686275, 0.37254902, 0.27843137],\n",
       "         [0.34117647, 0.35294118, 0.27843137],\n",
       "         [0.30980392, 0.31764706, 0.2745098 ]],\n",
       "\n",
       "        [[0.54901961, 0.62745098, 0.6627451 ],\n",
       "         [0.56862745, 0.6       , 0.60392157],\n",
       "         [0.49019608, 0.49019608, 0.4627451 ],\n",
       "         ...,\n",
       "         [0.37647059, 0.38823529, 0.30588235],\n",
       "         [0.30196078, 0.31372549, 0.24313725],\n",
       "         [0.27843137, 0.28627451, 0.23921569]],\n",
       "\n",
       "        [[0.54901961, 0.60784314, 0.64313725],\n",
       "         [0.54509804, 0.57254902, 0.58431373],\n",
       "         [0.45098039, 0.45098039, 0.43921569],\n",
       "         ...,\n",
       "         [0.30980392, 0.32156863, 0.25098039],\n",
       "         [0.26666667, 0.2745098 , 0.21568627],\n",
       "         [0.2627451 , 0.27058824, 0.21568627]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.68627451, 0.65490196, 0.65098039],\n",
       "         [0.61176471, 0.60392157, 0.62745098],\n",
       "         [0.60392157, 0.62745098, 0.66666667],\n",
       "         ...,\n",
       "         [0.16470588, 0.13333333, 0.14117647],\n",
       "         [0.23921569, 0.20784314, 0.22352941],\n",
       "         [0.36470588, 0.3254902 , 0.35686275]],\n",
       "\n",
       "        [[0.64705882, 0.60392157, 0.50196078],\n",
       "         [0.61176471, 0.59607843, 0.50980392],\n",
       "         [0.62352941, 0.63137255, 0.55686275],\n",
       "         ...,\n",
       "         [0.40392157, 0.36470588, 0.37647059],\n",
       "         [0.48235294, 0.44705882, 0.47058824],\n",
       "         [0.51372549, 0.4745098 , 0.51372549]],\n",
       "\n",
       "        [[0.63921569, 0.58039216, 0.47058824],\n",
       "         [0.61960784, 0.58039216, 0.47843137],\n",
       "         [0.63921569, 0.61176471, 0.52156863],\n",
       "         ...,\n",
       "         [0.56078431, 0.52156863, 0.54509804],\n",
       "         [0.56078431, 0.5254902 , 0.55686275],\n",
       "         [0.56078431, 0.52156863, 0.56470588]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         ...,\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         ...,\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.44313725, 0.47058824, 0.43921569],\n",
       "         [0.43529412, 0.4627451 , 0.43529412],\n",
       "         [0.41176471, 0.43921569, 0.41568627],\n",
       "         ...,\n",
       "         [0.28235294, 0.31764706, 0.31372549],\n",
       "         [0.28235294, 0.31372549, 0.30980392],\n",
       "         [0.28235294, 0.31372549, 0.30980392]],\n",
       "\n",
       "        [[0.43529412, 0.4627451 , 0.43137255],\n",
       "         [0.40784314, 0.43529412, 0.40784314],\n",
       "         [0.38823529, 0.41568627, 0.38431373],\n",
       "         ...,\n",
       "         [0.26666667, 0.29411765, 0.28627451],\n",
       "         [0.2745098 , 0.29803922, 0.29411765],\n",
       "         [0.30588235, 0.32941176, 0.32156863]],\n",
       "\n",
       "        [[0.41568627, 0.44313725, 0.41176471],\n",
       "         [0.38823529, 0.41568627, 0.38431373],\n",
       "         [0.37254902, 0.4       , 0.36862745],\n",
       "         ...,\n",
       "         [0.30588235, 0.33333333, 0.3254902 ],\n",
       "         [0.30980392, 0.33333333, 0.3254902 ],\n",
       "         [0.31372549, 0.3372549 , 0.32941176]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.1372549 , 0.69803922, 0.92156863],\n",
       "         [0.15686275, 0.69019608, 0.9372549 ],\n",
       "         [0.16470588, 0.69019608, 0.94509804],\n",
       "         ...,\n",
       "         [0.38823529, 0.69411765, 0.85882353],\n",
       "         [0.30980392, 0.57647059, 0.77254902],\n",
       "         [0.34901961, 0.58039216, 0.74117647]],\n",
       "\n",
       "        [[0.22352941, 0.71372549, 0.91764706],\n",
       "         [0.17254902, 0.72156863, 0.98039216],\n",
       "         [0.19607843, 0.71764706, 0.94117647],\n",
       "         ...,\n",
       "         [0.61176471, 0.71372549, 0.78431373],\n",
       "         [0.55294118, 0.69411765, 0.80784314],\n",
       "         [0.45490196, 0.58431373, 0.68627451]],\n",
       "\n",
       "        [[0.38431373, 0.77254902, 0.92941176],\n",
       "         [0.25098039, 0.74117647, 0.98823529],\n",
       "         [0.27058824, 0.75294118, 0.96078431],\n",
       "         ...,\n",
       "         [0.7372549 , 0.76470588, 0.80784314],\n",
       "         [0.46666667, 0.52941176, 0.57647059],\n",
       "         [0.23921569, 0.30980392, 0.35294118]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.28627451, 0.30980392, 0.30196078],\n",
       "         [0.20784314, 0.24705882, 0.26666667],\n",
       "         [0.21176471, 0.26666667, 0.31372549],\n",
       "         ...,\n",
       "         [0.06666667, 0.15686275, 0.25098039],\n",
       "         [0.08235294, 0.14117647, 0.2       ],\n",
       "         [0.12941176, 0.18823529, 0.19215686]],\n",
       "\n",
       "        [[0.23921569, 0.26666667, 0.29411765],\n",
       "         [0.21568627, 0.2745098 , 0.3372549 ],\n",
       "         [0.22352941, 0.30980392, 0.40392157],\n",
       "         ...,\n",
       "         [0.09411765, 0.18823529, 0.28235294],\n",
       "         [0.06666667, 0.1372549 , 0.20784314],\n",
       "         [0.02745098, 0.09019608, 0.1254902 ]],\n",
       "\n",
       "        [[0.17254902, 0.21960784, 0.28627451],\n",
       "         [0.18039216, 0.25882353, 0.34509804],\n",
       "         [0.19215686, 0.30196078, 0.41176471],\n",
       "         ...,\n",
       "         [0.10588235, 0.20392157, 0.30196078],\n",
       "         [0.08235294, 0.16862745, 0.25882353],\n",
       "         [0.04705882, 0.12156863, 0.19607843]]],\n",
       "\n",
       "\n",
       "       [[[0.74117647, 0.82745098, 0.94117647],\n",
       "         [0.72941176, 0.81568627, 0.9254902 ],\n",
       "         [0.7254902 , 0.81176471, 0.92156863],\n",
       "         ...,\n",
       "         [0.68627451, 0.76470588, 0.87843137],\n",
       "         [0.6745098 , 0.76078431, 0.87058824],\n",
       "         [0.6627451 , 0.76078431, 0.8627451 ]],\n",
       "\n",
       "        [[0.76078431, 0.82352941, 0.9372549 ],\n",
       "         [0.74901961, 0.81176471, 0.9254902 ],\n",
       "         [0.74509804, 0.80784314, 0.92156863],\n",
       "         ...,\n",
       "         [0.67843137, 0.75294118, 0.8627451 ],\n",
       "         [0.67058824, 0.74901961, 0.85490196],\n",
       "         [0.65490196, 0.74509804, 0.84705882]],\n",
       "\n",
       "        [[0.81568627, 0.85882353, 0.95686275],\n",
       "         [0.80392157, 0.84705882, 0.94117647],\n",
       "         [0.8       , 0.84313725, 0.9372549 ],\n",
       "         ...,\n",
       "         [0.68627451, 0.74901961, 0.85098039],\n",
       "         [0.6745098 , 0.74509804, 0.84705882],\n",
       "         [0.6627451 , 0.74901961, 0.84313725]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.81176471, 0.78039216, 0.70980392],\n",
       "         [0.79607843, 0.76470588, 0.68627451],\n",
       "         [0.79607843, 0.76862745, 0.67843137],\n",
       "         ...,\n",
       "         [0.52941176, 0.51764706, 0.49803922],\n",
       "         [0.63529412, 0.61960784, 0.58823529],\n",
       "         [0.65882353, 0.63921569, 0.59215686]],\n",
       "\n",
       "        [[0.77647059, 0.74509804, 0.66666667],\n",
       "         [0.74117647, 0.70980392, 0.62352941],\n",
       "         [0.70588235, 0.6745098 , 0.57647059],\n",
       "         ...,\n",
       "         [0.69803922, 0.67058824, 0.62745098],\n",
       "         [0.68627451, 0.6627451 , 0.61176471],\n",
       "         [0.68627451, 0.6627451 , 0.60392157]],\n",
       "\n",
       "        [[0.77647059, 0.74117647, 0.67843137],\n",
       "         [0.74117647, 0.70980392, 0.63529412],\n",
       "         [0.69803922, 0.66666667, 0.58431373],\n",
       "         ...,\n",
       "         [0.76470588, 0.72156863, 0.6627451 ],\n",
       "         [0.76862745, 0.74117647, 0.67058824],\n",
       "         [0.76470588, 0.74509804, 0.67058824]]],\n",
       "\n",
       "\n",
       "       [[[0.89803922, 0.89803922, 0.9372549 ],\n",
       "         [0.9254902 , 0.92941176, 0.96862745],\n",
       "         [0.91764706, 0.9254902 , 0.96862745],\n",
       "         ...,\n",
       "         [0.85098039, 0.85882353, 0.91372549],\n",
       "         [0.86666667, 0.8745098 , 0.91764706],\n",
       "         [0.87058824, 0.8745098 , 0.91372549]],\n",
       "\n",
       "        [[0.87058824, 0.86666667, 0.89803922],\n",
       "         [0.9372549 , 0.9372549 , 0.97647059],\n",
       "         [0.91372549, 0.91764706, 0.96470588],\n",
       "         ...,\n",
       "         [0.8745098 , 0.8745098 , 0.9254902 ],\n",
       "         [0.89019608, 0.89411765, 0.93333333],\n",
       "         [0.82352941, 0.82745098, 0.8627451 ]],\n",
       "\n",
       "        [[0.83529412, 0.80784314, 0.82745098],\n",
       "         [0.91764706, 0.90980392, 0.9372549 ],\n",
       "         [0.90588235, 0.91372549, 0.95686275],\n",
       "         ...,\n",
       "         [0.8627451 , 0.8627451 , 0.90980392],\n",
       "         [0.8627451 , 0.85882353, 0.90980392],\n",
       "         [0.79215686, 0.79607843, 0.84313725]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.58823529, 0.56078431, 0.52941176],\n",
       "         [0.54901961, 0.52941176, 0.49803922],\n",
       "         [0.51764706, 0.49803922, 0.47058824],\n",
       "         ...,\n",
       "         [0.87843137, 0.87058824, 0.85490196],\n",
       "         [0.90196078, 0.89411765, 0.88235294],\n",
       "         [0.94509804, 0.94509804, 0.93333333]],\n",
       "\n",
       "        [[0.5372549 , 0.51764706, 0.49411765],\n",
       "         [0.50980392, 0.49803922, 0.47058824],\n",
       "         [0.49019608, 0.4745098 , 0.45098039],\n",
       "         ...,\n",
       "         [0.70980392, 0.70588235, 0.69803922],\n",
       "         [0.79215686, 0.78823529, 0.77647059],\n",
       "         [0.83137255, 0.82745098, 0.81176471]],\n",
       "\n",
       "        [[0.47843137, 0.46666667, 0.44705882],\n",
       "         [0.4627451 , 0.45490196, 0.43137255],\n",
       "         [0.47058824, 0.45490196, 0.43529412],\n",
       "         ...,\n",
       "         [0.70196078, 0.69411765, 0.67843137],\n",
       "         [0.64313725, 0.64313725, 0.63529412],\n",
       "         [0.63921569, 0.63921569, 0.63137255]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n",
    "#plot_sample(X_train, Y_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 128)       3584      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 128)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        73792     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                147520    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 227,306\n",
      "Trainable params: 227,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build model with layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotLossAccuracyCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.train_losses = []  # Train loss\n",
    "        self.val_losses = []    # Validation loss\n",
    "        self.train_accuracy = [] # Train accuracy\n",
    "        self.val_accuracy = [] # Validation accuracy\n",
    "        self.fig, (self.ax1, self.ax2) = plt.subplots(1, 2, figsize=(12,4))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        #Adjust x axis to start from 1 instead of 0\n",
    "        epoch = epoch + 1\n",
    "\n",
    "        self.train_losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.train_accuracy.append(logs.get('accuracy'))         # Train accuracy\n",
    "        self.val_accuracy.append(logs.get('val_accuracy'))      # Validation accuracy\n",
    "\n",
    "        # Plot loss in the left subplot for loss\n",
    "        self.ax1.cla()\n",
    "        self.ax1.plot(range(1, epoch+1), self.train_losses, label=\"train loss\")\n",
    "        self.ax1.plot(range(1, epoch+1), self.val_losses, label=\"validation loss\")\n",
    "        self.ax1.set_title('Loss')\n",
    "        self.ax1.set_xlabel('Epoch')\n",
    "        self.ax1.set_ylabel('Loss')\n",
    "        self.ax1.legend()\n",
    "\n",
    "        # Plot accuracy in the right subplot for accuracy\n",
    "        self.ax2.cla()\n",
    "        self.ax2.plot(range(1, epoch+1), self.train_accuracy, label=\"train accuracy\")\n",
    "        self.ax2.plot(range(1, epoch+1), self.val_accuracy, label=\"validation accuracy\")\n",
    "        self.ax2.set_title('Accuracy')\n",
    "        self.ax2.set_xlabel('Epoch')\n",
    "        self.ax2.set_ylabel('Accuracy')\n",
    "        self.ax2.legend()\n",
    "\n",
    "        IPython.display.clear_output(wait=True)\n",
    "        IPython.display.display(self.fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 427/1563 [=======>......................] - ETA: 33s - loss: 2.0660 - accuracy: 0.2414"
     ]
    }
   ],
   "source": [
    "#Compile the model\n",
    "Myoptimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=Myoptimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "plot_loss_accuracy = PlotLossAccuracyCallback()\n",
    "\n",
    "#Train the model\n",
    "history = model.fit(X_train,\n",
    "                    Y_train, \n",
    "                    epochs=30, \n",
    "                    validation_data=(X_test, Y_test),\n",
    "                    callbacks=[plot_loss_accuracy]\n",
    "                    )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
